{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the EAGLE simulation data\n",
    "\n",
    "Write out the function for loading the EAGLE simulation data.  It checks whether reduced resolution versions have been created already and loads those if it has.\n",
    "\n",
    "The main function called in this script is \"loaddata\".\n",
    "It accepts a limited range of inputs, for the distance at which we are pretending to observe the simulated data and the \"slice width\" of the simulation (which corresponds to the filter width of the H$\\alpha$ NB filter).  The third input is the desired resolution of the image (i.e. binned resolution), which can be anything, but there are a few standards listed below.\n",
    "\n",
    "loaddata returns a data tuple which contains [data array, resolution, trimmed original data array shape]. <br>\n",
    "The \"trimmed original data array shape\" is the size of the original data array (32000x32000 from the 100Mpc size simulation) but trimmed by the amount that was needed in order to reduce the resolution of the simulation.  E.g. if the data needs to be reduced by a factor of 7, that does not go evenly into 32000, so before the data resolution is reduced, the data array is trimmed to a slightly smaller size that is factorable by 7.  This is recorded so we can determine the transverse distances accurately for plotting and masking later on.\n",
    "\n",
    "An accompanying script, load_data_testing.ipynb, tests the functionality of this script by providing and running some examples.\n",
    "\n",
    "### Distance:\n",
    "Distance must be one of: 50Mpc, 100Mpc, 200Mpc, or 500Mpc. <br> To expand this range, we will need to add in the cosmology calculator to calculate the distance-arcsecond transverse scaling at that distance.\n",
    "\n",
    "### Slice Width:\n",
    "The EAGLE simulations are projected into slice widths of 5Mpc, covering 20 Mpc of width in total (z = 0 to 20 Mpc).  The desired slice width must be one of: 5Mpc, 10Mpc, 15Mpc, or 20Mpc.  Roughly, this corresponds to filter widths of 1nm to 5nm.\n",
    "\n",
    "### Resolution:\n",
    "You can input any resolution (in arcseconds), but some standards are:  14 arcsec, 100 arcsec, 500 arcsec, 1000 arcsec<br>\n",
    "The minimum resolution of the EAGLE simulation is 13 (6.4,3.2,1.3) arcsec per pixel at a distance of 50 (100,200,500) Mpc.  Since Dragonfly pixels are 2.8 arcsec in size, let's pick 2.8 arcsec*5 = 14 arcsec as the smallest consistent resolution for each distance.  This just makes things easier when comparing how much we have to bin at each distance (since if we can compare the same angular resolution at each distance this becomes a little easier, rather than comparing the different minimum angular resolution at each distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs:\n",
    "homedir<br>\n",
    "basedir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import eagle_constants_and_units as c\n",
    "import cosmo_utils as csu\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import mpl_toolkits.axes_grid1 as axgrid\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "\n",
    "import os\n",
    "\n",
    "#import get_halpha_SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imreduce_masked(img,factor,log=True,fillby='max'):\n",
    "    \"\"\"\n",
    "    reduces the resolution of an image by taking the mean of individual elements\n",
    "    takes in a mask to mask out values to be not included in the mean\n",
    "        img: 2D image array\n",
    "        mask: mask for the 2D image array\n",
    "        factor: factor by which to reduce the number of array elements along each axis\n",
    "    examples:\n",
    "    for testing: \n",
    "        image = np.array([[1,1,2,2],[1,201,2,2],[3,3,200,4],[3,3,4,4]])\n",
    "    mask your mask like this:  \n",
    "        clipped = sigma_clip(image,sig=3,iters=2)\n",
    "        mask = clipped.mask\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "def imreduce(img, factor, log=True, method = 'average'):\n",
    "    \"\"\"\n",
    "    img: 2D image array\n",
    "    factor: factor by which to reduce the number of array elements along each axis\n",
    "    log: whether or not the array contains log data values\n",
    "    \"\"\"\n",
    "    if log:\n",
    "        inimg = 10**img\n",
    "    else:\n",
    "        inimg = img\n",
    "    inshape = np.array(img.shape)\n",
    "\n",
    "    if np.sum(inshape%factor) != 0:\n",
    "        print('Output grid must have a integer number of cells: cannot reduce image pixels by a factor %i'%factor)\n",
    "        return None\n",
    "    inimg = np.array(np.split(inimg,inshape[0]/factor,axis=0))\n",
    "    inimg = np.array(np.split(inimg,inshape[1]/factor,axis=-1))\n",
    "\n",
    "    inimg = np.sum(inimg,axis=-1)\n",
    "    inimg = np.sum(inimg,axis=-1)\n",
    "    \n",
    "    if method == 'average':\n",
    "        inimg = inimg/np.float(factor**2)\n",
    "        #outimg = np.average(inimg[])\n",
    "    if log:\n",
    "        inimg = np.log10(inimg)\n",
    "    return inimg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initstuff(testing):\n",
    "    global homedir\n",
    "    global files_SF_28\n",
    "    global files_noSF_28\n",
    "    homedir=''\n",
    "    if machine=='chinook':\n",
    "        homedir='/Users/lokhorst/Eagle/'\n",
    "    elif machine=='coho':\n",
    "        homedir='/Users/deblokhorst/eagle/SlicesFromNastasha/'\n",
    "    ## Add the path to where the raw data is kept on your computer here\n",
    "    \n",
    "    files_SF_28 = [homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen12.5__fromSFR.npz',\n",
    "                    homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen17.5__fromSFR.npz',\n",
    "                    homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen2.5__fromSFR.npz',\n",
    "                    homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen7.5__fromSFR.npz']\n",
    "\n",
    "    files_noSF_28 = [homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen12.5_noSFR.npz',\n",
    "                    homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen17.5_noSFR.npz',\n",
    "                    homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen2.5_noSFR.npz',\n",
    "                    homedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen7.5_noSFR.npz']\n",
    "\n",
    "    if testing:\n",
    "        'define an array to be used for testing - this will be in log10'\n",
    "        size   = 320\n",
    "        maxval = 10.\n",
    "        fakedata = np.array([[x/(size/maxval)-maxval/2. for x in range(size)] for y in range(size)])\n",
    "        np.savez(homedir+'fakedata.npz',fakedata)\n",
    "        files_SF_28 = [homedir+'fakedata.npz',homedir+'fakedata.npz',homedir+'fakedata.npz',homedir+'fakedata.npz']\n",
    "        files_noSF_28 = [homedir+'fakedata.npz',homedir+'fakedata.npz',homedir+'fakedata.npz',homedir+'fakedata.npz']\n",
    "        \n",
    "    sl = [slice(None,None,None), slice(None,None,None)]\n",
    "    \n",
    "    return homedir,files_SF_28,files_noSF_28,sl\n",
    "\n",
    "def changeres(distance,resolution,data):\n",
    "    \"\"\"\n",
    "    distance: one of 50Mpc, 100Mpc, 200Mpc, or 500Mpc\n",
    "    resolution: desired output resolution (e.g. 14 arcsec, 100 arcsec, 500 arcsec, 1000 arcsec)\n",
    "    data: the raw data (size 32000 x 32000 pixels, 100 Mpc x 100 Mpc)\n",
    "    \"\"\"\n",
    "    pixscale_tomatchres = {'46Mpc': 0.221/1000.*(1.+0.0107),'92Mpc':0.437/1000.*(1.+0.0215)}\n",
    "    pixscale            = {'50Mpc': 0.237/1000.*(1.+0.0115), '100Mpc': 0.477/1000.*(1.+0.0235),\\\n",
    "                           '200Mpc': 0.928/1000.*(1.+0.047) , '500Mpc': 2.178/1000.*(1.+0.12)} ### Mpc / arcsec (comoving)\n",
    "    size = 32000. # pixels \n",
    "    scale = 100.  # Mpc \n",
    "    \n",
    "    if dotests:\n",
    "        print \"TESTING IS TRUE in changeres\"\n",
    "        size  = 320. # pixels\n",
    "        scale = 1.   # Mpc\n",
    "    \n",
    "    if distance in pixscale:\n",
    "        simpixsize = scale/size ### Mpc / pixel is resolution of raw data \n",
    "        factor = round(pixscale[distance]*resolution/simpixsize)\n",
    "        print(\"Will reduce resolution by a factor of %s.\"%factor)\n",
    "        # LATER determine the current resolution of the data. FOR NOW assume current resolution is 100 Mpc/ 32000 pixels ~ 3 kpc/pixel\n",
    "\n",
    "        'If the factors are not integer multiples of the size (32000), trim the data first and then imreduce it'\n",
    "        if size%((factor)) != 0.:\n",
    "            times_factor_fits_in = int(size/factor)\n",
    "            newsize = times_factor_fits_in * factor\n",
    "            print(\"Before reducing resolution, the original data was trimmed to size %s.\"%newsize)\n",
    "            datanew = data[0:int(newsize),0:int(newsize)]\n",
    "        else:\n",
    "            datanew = data\n",
    "            newsize = size\n",
    "    else:\n",
    "        print('distance needs to be one of: 50Mpc, 100Mpc, 200Mpc, or 500Mpc.  Others not supported atm.')\n",
    "        return None\n",
    "    \n",
    "    if factor < 2.:\n",
    "        return datanew, newsize, factor\n",
    "    else:\n",
    "        return imreduce(datanew, round(factor), log=True, method = 'average'), newsize, factor\n",
    "\n",
    "\n",
    "def loadraw(files_SF_28,files_noSF_28,sl,index=0):\n",
    "    print('Loading noSF data first ('+files_noSF_28[index]+')...')\n",
    "    data1 = (np.load(files_noSF_28[index])['arr_0'])[sl]\n",
    "    print('Loading SF data second ('+files_SF_28[index]+')...')\n",
    "    data11 = (np.load(files_SF_28[index])['arr_0'])[sl]\n",
    "    print('Adding together to make a 5 Mpc slice...')\n",
    "    data = np.log10(10**data1+10**data11)\n",
    "    print('Deleting intermediate files: noSF data, SF data...')\n",
    "    del data1\n",
    "    del data11\n",
    "    return data\n",
    "\n",
    "def load5Mpcslice(files_SF_28,files_noSF_28,sl):\n",
    "    print('Loading a 5Mpc slice of data...')        \n",
    "    'check if the SF plus noSF data file already exists...'\n",
    "    total_fname = basedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen12.5_total.npz'\n",
    "    if os.path.isfile(total_fname):\n",
    "        print(\"Data exists, loading %s now...\"%total_fname)\n",
    "        data = (np.load(total_fname)['arr_0'])[sl]\n",
    "    else:\n",
    "        print(\"Data not saved, loading from original files now...\")\n",
    "        data = loadraw(files_SF_28,files_noSF_28,sl)\n",
    "        print(\"Saving the summed data in %s...\"%total_fname)\n",
    "        np.savez(total_fname,data)\n",
    "    return data\n",
    "\n",
    "def loadslice(slicewidth,numslices,files_SF_28,files_noSF_28,sl):\n",
    "    total_fname = basedir+'emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_%sslice_zcen12.5_total.npz'\\\n",
    "                    %slicewidth\n",
    "    if os.path.isfile(total_fname):\n",
    "        print(\"Data exists, loading %s now...\"%total_fname)\n",
    "        data = (np.load(total_fname)['arr_0'])[sl]\n",
    "    else:\n",
    "        print('Creating data of slicewidth %s Mpc (%s does not yet exist)...'\\\n",
    "              %(slicewidth,total_fname))\n",
    "        print('First slice: index %s of %s'%(1,numslices))\n",
    "        data = loadraw(files_SF_28,files_noSF_28,sl,index=0)\n",
    "        for index in range(numslices-1):\n",
    "            print('Next slice: index %s of %s'%(index+1,numslices))\n",
    "            rawdata = loadraw(files_SF_28,files_noSF_28,sl,index=index+1)  \n",
    "            data = np.log10(10**data+10**rawdata)\n",
    "        print(\"Saving the summed data in %s...\"%total_fname)\n",
    "        del rawdata\n",
    "        np.savez(total_fname,data)    \n",
    "    return data\n",
    "    \n",
    "def loaddata(machine='coho',resolution=None, distance=None, slicewidth=5, testing=False):\n",
    "    \"\"\"\n",
    "    Returns a tuple containing the data in the first index\n",
    "    It contains the size of the data before resolution was reduced in the second index (just its own size if raw data)\n",
    "    It contains the factor by which the data was reduced in the third index (just '1' if raw data)\n",
    "    \"\"\"\n",
    "    homedir,files_SF_28,files_noSF_28,sl = initstuff(testing) # Simulation snapnum 28 (z = 0), xy box size: 100Mpc, z slice width: 5Mpc,\n",
    "    global basedir\n",
    "    global dotests\n",
    "    dotests = False\n",
    "    if testing:\n",
    "        dotests = True\n",
    "    basedir ='./intermediatedata/'\n",
    "    if testing:\n",
    "        basedir=basedir+'testing/'\n",
    "    ## Can change the basedir of where your intermediatedata files will live here\n",
    "    \n",
    "    'Create outdir if it does not exist'\n",
    "    if not os.path.isdir(basedir):\n",
    "        os.makedirs(basedir)\n",
    "    \n",
    "    if resolution is None and distance is None and int(slicewidth) == 5:\n",
    "        data = load5Mpcslice(files_SF_28,files_noSF_28,sl)\n",
    "        data = np.array([data,data.shape[0],1]) # make into a tuple\n",
    "        \n",
    "    elif resolution is not None and int(slicewidth) == 5:\n",
    "        # Note: Once the data has new resolution, it is saved as a tuple, with extra info\n",
    "        # The format of the tuple is: data, trimmed_data_size_before_reducing, factor_by_which_reduced\n",
    "        if distance is None:\n",
    "            print('Need to input both a distance and a resolution. Exiting.')\n",
    "            return None\n",
    "        fname = basedir+'data_%s_%sarcsec.npz'%(str(distance),int(resolution))\n",
    "        \n",
    "        if fname == basedir+'data_50Mpc_14arcsec.npz':\n",
    "            print ('%s exists (and is special because cant save as tuple), loading now...'%fname)\n",
    "            sl = [slice(None,None,None), slice(None,None,None)]\n",
    "            data = (np.load(fname)['arr_0'])[sl]\n",
    "            return data,32000.,1.\n",
    "        \n",
    "        if os.path.isfile(fname):\n",
    "            print('%s exists, loading now...'%fname)\n",
    "            data_tuple = (np.load(fname)['arr_0'])\n",
    "        else:\n",
    "            print('%s does not exist, making it now...'%fname)\n",
    "            rawdata = load5Mpcslice(files_SF_28,files_noSF_28,sl)\n",
    "            print(\"Reducing the resolution to desired distance/resolution...\")\n",
    "            data_tuple = changeres(distance,resolution,rawdata)\n",
    "            print(\"Saving the data to %s...\"%fname)\n",
    "            np.savez(fname,data_tuple)\n",
    "        data = data_tuple # save the tuple to data\n",
    "\n",
    "    elif int(slicewidth) != 5:\n",
    "        numslices = int(round(slicewidth / 5.))\n",
    "        slicewidth = int(numslices * 5.)\n",
    "        print(\"Loading data of slicewidth %s (after rounding), number of slices is %s\"\\\n",
    "              %(slicewidth,numslices))                   \n",
    "        if resolution is not None:\n",
    "            if distance is None:\n",
    "                print('Need to input both a distance and a resolution.  Exiting.')\n",
    "                return None\n",
    "            fname = basedir+'data_%s_%sarcsec_%sslwd.npz'%(str(distance),int(resolution),int(slicewidth))\n",
    "\n",
    "            if fname == basedir+'data_50Mpc_14arcsec_20slwd.npz':\n",
    "                if os.path.isfile(fname):\n",
    "                    print ('%s exists (and is special because cant save as tuple), loading now...'%fname)\n",
    "                    sl = [slice(None,None,None), slice(None,None,None)]\n",
    "                    data = (np.load(fname)['arr_0'])[sl]\n",
    "                    return data,32000.,1.\n",
    "                else:\n",
    "                    print ('%s doesnt exist yet (but is special because cant save as tuple and is equal to the raw data), copying from...'%fname)\n",
    "                    fulldata = loadslice(slicewidth,numslices,files_SF_28,files_noSF_28,sl)\n",
    "                    print ('Saving %s as %s' %(fulldata,fname))\n",
    "                    np.savez(fname,fulldata)\n",
    "                    return fulldata,32000.,1.\n",
    "                    \n",
    "            if os.path.isfile(fname):\n",
    "                print('%s exists, loading now...'%fname)\n",
    "                data_tuple = (np.load(fname)['arr_0'])\n",
    "            else:\n",
    "                print('%s does not exist, making it now...'%fname)\n",
    "                fulldata = loadslice(slicewidth,numslices,files_SF_28,files_noSF_28,sl)\n",
    "                print(\"Reducing the resolution to desired distance/resolution...\")\n",
    "                data_tuple = changeres(distance,resolution,fulldata)\n",
    "                print(\"DEBUGGING: data_tuple is: \")\n",
    "                print data_tuple\n",
    "                print(\"Saving the data to %s...\"%fname)\n",
    "                np.savez(fname,data_tuple)\n",
    "            data = data_tuple # save the tuple to data\n",
    "\n",
    "        else:\n",
    "            data = loadslice(slicewidth,numslices,files_SF_28,files_noSF_28,sl)\n",
    "            data = np.array([data,data.shape[0],1]) # make into a tuple\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TESTING SCRIPT ##\n",
    "#machine = 'chinook'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a 5Mpc slice of data...\n",
      "data exists, loading emission_halpha_L0100N1504_28_test2_SmAb_C2Sm_32000pix_5.000000slice_zcen12.5_total.npz now...\n"
     ]
    }
   ],
   "source": [
    "### EXAMPLES ###\n",
    "#machine='coho'\n",
    "\n",
    "#distance = '50Mpc'; resolution = 100\n",
    "#data_tuple = loaddata(machine=machine,resolution=resolution,distance=distance)\n",
    "#data = data_tuple[0]\n",
    "\n",
    "#data_tuple = loaddata(machine=machine)\n",
    "#data = data_tuple[0]\n",
    "######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
